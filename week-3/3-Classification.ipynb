{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 - Classification\n",
    "\n",
    "This week, we shift from gathering human textual classifications through crowdsourcing, to using machine learning models and algorithms that train on those human classifications and extend them to documents far too numerous to read. If you recall, *clustering* allows us to stably partition text data (e.g., documents, turns of conversation) according to all patterns of covariation among available text features. *Classification*, by contrast, partitions text data according to only those features and their variation that enable us to mimic and extrapolate human annotations.\n",
    "\n",
    "In this notebook, we will show how to use a variety of classification methods, including Na√Øve Bayes, Logistic regression, K-nearest neighbor, decision trees and random forests, support vector machines and even a simple neural network, the perceptron. We will also demonstrate ensemble techniques that can link several such methods into a single, more accurate, classification pipeline. We will finally learn to use conventions and metrics to evaluate classifier performance on out-of-sample data. \n",
    "\n",
    "For this notebook we will be using the following packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special module written for this class\n",
    "#This provides access to data and to helper functions from previous weeks\n",
    "#Make sure you update it before starting this notebook\n",
    "import lucem_illud_2020 #pip install -U git+git://github.com/Computational-Content-Analysis-2020/lucem_illud_2020.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "#For ML\n",
    "import sklearn\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "import sklearn.neural_network\n",
    "import sklearn.decomposition\n",
    "\n",
    "import numpy as np #arrays\n",
    "import matplotlib.pyplot as plt #Plots\n",
    "import matplotlib.colors # For nice colours\n",
    "import seaborn #Makes plots look nice, also heatmaps\n",
    "import scipy as sp #for interp\n",
    "\n",
    "#These are from the standard library\n",
    "import collections\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import glob\n",
    "import pandas\n",
    "import requests\n",
    "import json\n",
    "import math\n",
    "\n",
    "#This 'magic' command makes the plots work better\n",
    "#in the notebook, don't use it outside of a notebook.\n",
    "#Also you can ignore the warning\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Simulated Examples\n",
    "\n",
    "Here we create a sandbox for you to explore different types of classified data and how different statistical classifiers perform on each type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating example data\n",
    "\n",
    "We start by loading one of the \"cartoon\" or simplified data sets and then dividing it into training and testing sets. To maximize our ability to visualize, each dataset involves two classes, colored yellow and blue, arrayed along two two dimensions (`x` and `y`). \n",
    "\n",
    "The four data patterns include: \n",
    "+ `random` in which the two classes are randomly distributed across both dimensions\n",
    "+ `andSplit` in which the two classes are linearly split along one of two dimensions (e.g., men like Adidas)\n",
    "+ `xorSplit` in which the two classes are split, oppositely, along each dimension (e.g., old ladies and young men like Nikes)\n",
    "+ `targetSplit` in which one class is nested within the other in two dimensions (e.g., middle aged, middle income people like vintage Mustangs)\n",
    "+ `multiBlobs` in which 5 classes are placed as bivariate Gaussians at random locations\n",
    "\n",
    "`noise` is a variable [0-1] that ranges from no noise in the prescribed pattern [0] to complete noise/randomness [1].\n",
    "\n",
    "Uncomment (remove the # in front of) each dataset, one at a time, and then run the cell and subsequent cells to examine how each machine learning approach captures each pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = .2\n",
    "\n",
    "#dfTrain, dfTest = lucem_illud_2020.trainTestSplit(lucem_illud_2020.random())\n",
    "#dfTrain, dfTest = lucem_illud_2020.trainTestSplit(lucem_illud_2020.andSplit(noise))\n",
    "#dfTrain, dfTest = lucem_illud_2020.trainTestSplit(lucem_illud_2020.xorSplit(noise)) #Please try this one\n",
    "dfTrain, dfTest = lucem_illud_2020.trainTestSplit(lucem_illud_2020.targetSplit(noise))\n",
    "#dfTrain, dfTest = lucem_illud_2020.trainTestSplit(lucem_illud_2020.multiBlobs(noise))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily visualize the rendered datasets because they are generated in two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lucem_illud_2020.plotter(dfTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vect</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>[0.10993846386303634, 0.18704342692037915]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>[-0.5188411983349279, -0.1079212278252057]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>[0.06911962035154608, 0.39224273437116597]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>[0.3916850798670615, -0.7529503717328117]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>[0.22014070876926944, 0.09835344458937535]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           vect  category\n",
       "258  [0.10993846386303634, 0.18704342692037915]         0\n",
       "515  [-0.5188411983349279, -0.1079212278252057]         1\n",
       "163  [0.06911962035154608, 0.39224273437116597]         1\n",
       "751   [0.3916850798670615, -0.7529503717328117]         1\n",
       "684  [0.22014070876926944, 0.09835344458937535]         0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Machine Learning algorithm\n",
    "\n",
    "We can now pick a model, there are many more options in `scikit-learn`. These are just a few examples, which array along the machine learning \"tribes\" described in Pedro Domingos _The Master Algorithm_.\n",
    "\n",
    "Uncomment (remove the # in front of) each algorithm one at a time, then run the cell and subsequent cells to evaluate how it learns to understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayes\n",
    "#clf = sklearn.naive_bayes.GaussianNB()\n",
    "\n",
    "#Analogizes\n",
    "#clf = sklearn.svm.SVC(kernel = 'linear', probability = True) #slow, set probability = False to speed up\n",
    "#clf = sklearn.svm.SVC(kernel = 'poly', degree = 3, probability = True) #slower\n",
    "#clf = sklearn.neighbors.KNeighborsClassifier(5, weights='distance')# k, 'distance' or 'uniform'\n",
    "\n",
    "#Classical Regression\n",
    "#clf = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "#Symbolists\n",
    "#clf = sklearn.tree.DecisionTreeClassifier()\n",
    "#clf = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "#Connectionists\n",
    "#clf = sklearn.neural_network.MLPClassifier()\n",
    "\n",
    "#Ensemble\n",
    "clf = sklearn.ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit the model by giving it our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(np.stack(dfTrain['vect'], axis=0), dfTrain['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm evaluation\n",
    "\n",
    "We can look at few measurements of each classifier's performance by using the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.49965</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.494825</td>\n",
       "      <td>0.464646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.49965</td>\n",
       "      <td>0.504673</td>\n",
       "      <td>0.504825</td>\n",
       "      <td>0.534653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Error_Rate      AUC  Precision  Average_Precision    Recall\n",
       "Category                                                             \n",
       "0                0.5  0.49965   0.494624           0.494825  0.464646\n",
       "1                0.5  0.49965   0.504673           0.504825  0.534653"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lucem_illud_2020.evaluateClassifier(clf, dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>methods</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.499650</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.494825</td>\n",
       "      <td>0.464646</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.499650</td>\n",
       "      <td>0.504673</td>\n",
       "      <td>0.504825</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.475898</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>0.483447</td>\n",
       "      <td>0.565657</td>\n",
       "      <td>Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.475898</td>\n",
       "      <td>0.475610</td>\n",
       "      <td>0.493651</td>\n",
       "      <td>0.386139</td>\n",
       "      <td>Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.480</td>\n",
       "      <td>0.520552</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.505659</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.480</td>\n",
       "      <td>0.520552</td>\n",
       "      <td>0.528090</td>\n",
       "      <td>0.515745</td>\n",
       "      <td>0.465347</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.474397</td>\n",
       "      <td>0.465909</td>\n",
       "      <td>0.482952</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>decision tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.474397</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.492779</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>decision tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.475</td>\n",
       "      <td>0.525303</td>\n",
       "      <td>0.518868</td>\n",
       "      <td>0.508260</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>logistic regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.475</td>\n",
       "      <td>0.525303</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.518324</td>\n",
       "      <td>0.495050</td>\n",
       "      <td>logistic regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.540</td>\n",
       "      <td>0.459646</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.476593</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>kNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.540</td>\n",
       "      <td>0.459646</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.486332</td>\n",
       "      <td>0.495050</td>\n",
       "      <td>kNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.445</td>\n",
       "      <td>0.557006</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.525844</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>SVM poly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.445</td>\n",
       "      <td>0.557006</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.538861</td>\n",
       "      <td>0.356436</td>\n",
       "      <td>SVM poly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.470</td>\n",
       "      <td>0.529953</td>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.510890</td>\n",
       "      <td>0.525253</td>\n",
       "      <td>SVM linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.470</td>\n",
       "      <td>0.529953</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>0.520854</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>SVM linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.490</td>\n",
       "      <td>0.510051</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.500126</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.490</td>\n",
       "      <td>0.510051</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.510126</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Error_Rate       AUC  Precision  Average_Precision    Recall  \\\n",
       "Category                                                                 \n",
       "0              0.500  0.499650   0.494624           0.494825  0.464646   \n",
       "1              0.500  0.499650   0.504673           0.504825  0.534653   \n",
       "0              0.525  0.475898   0.474576           0.483447  0.565657   \n",
       "1              0.525  0.475898   0.475610           0.493651  0.386139   \n",
       "0              0.480  0.520552   0.513514           0.505659  0.575758   \n",
       "1              0.480  0.520552   0.528090           0.515745  0.465347   \n",
       "0              0.525  0.474397   0.465909           0.482952  0.414141   \n",
       "1              0.525  0.474397   0.482143           0.492779  0.534653   \n",
       "0              0.475  0.525303   0.518868           0.508260  0.555556   \n",
       "1              0.475  0.525303   0.531915           0.518324  0.495050   \n",
       "0              0.540  0.459646   0.451613           0.476593  0.424242   \n",
       "1              0.540  0.459646   0.467290           0.486332  0.495050   \n",
       "0              0.445  0.557006   0.535714           0.525844  0.757576   \n",
       "1              0.445  0.557006   0.600000           0.538861  0.356436   \n",
       "0              0.470  0.529953   0.525253           0.510890  0.525253   \n",
       "1              0.470  0.529953   0.534653           0.520854  0.534653   \n",
       "0              0.490  0.510051   0.504950           0.500126  0.515152   \n",
       "1              0.490  0.510051   0.515152           0.510126  0.504950   \n",
       "\n",
       "                      methods  \n",
       "Category                       \n",
       "0           Gradient Boosting  \n",
       "1           Gradient Boosting  \n",
       "0              Neural Network  \n",
       "1              Neural Network  \n",
       "0               random forest  \n",
       "1               random forest  \n",
       "0               decision tree  \n",
       "1               decision tree  \n",
       "0         logistic regression  \n",
       "1         logistic regression  \n",
       "0                         kNN  \n",
       "1                         kNN  \n",
       "0                    SVM poly  \n",
       "1                    SVM poly  \n",
       "0                  SVM linear  \n",
       "1                  SVM linear  \n",
       "0                 Naive Bayes  \n",
       "1                 Naive Bayes  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Target sample\n",
    "pd0=lucem_illud_2020.evaluateClassifier(clf, dfTest)\n",
    "pd0['methods']='Gradient Boosting' #need to correct\n",
    "pd_random_sample=pandas.concat([pd0,pd_random_sample])\n",
    "pd_random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>methods</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.499650</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.494825</td>\n",
       "      <td>0.464646</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.499650</td>\n",
       "      <td>0.504673</td>\n",
       "      <td>0.504825</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.475898</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>0.483447</td>\n",
       "      <td>0.565657</td>\n",
       "      <td>Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.475898</td>\n",
       "      <td>0.475610</td>\n",
       "      <td>0.493651</td>\n",
       "      <td>0.386139</td>\n",
       "      <td>Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.480</td>\n",
       "      <td>0.520552</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.505659</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.480</td>\n",
       "      <td>0.520552</td>\n",
       "      <td>0.528090</td>\n",
       "      <td>0.515745</td>\n",
       "      <td>0.465347</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.474397</td>\n",
       "      <td>0.465909</td>\n",
       "      <td>0.482952</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>decision tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.474397</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.492779</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>decision tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.475</td>\n",
       "      <td>0.525303</td>\n",
       "      <td>0.518868</td>\n",
       "      <td>0.508260</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>logistic regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.475</td>\n",
       "      <td>0.525303</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.518324</td>\n",
       "      <td>0.495050</td>\n",
       "      <td>logistic regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.540</td>\n",
       "      <td>0.459646</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.476593</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>kNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.540</td>\n",
       "      <td>0.459646</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.486332</td>\n",
       "      <td>0.495050</td>\n",
       "      <td>kNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.445</td>\n",
       "      <td>0.557006</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.525844</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>SVM poly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.445</td>\n",
       "      <td>0.557006</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.538861</td>\n",
       "      <td>0.356436</td>\n",
       "      <td>SVM poly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.470</td>\n",
       "      <td>0.529953</td>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.510890</td>\n",
       "      <td>0.525253</td>\n",
       "      <td>SVM linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.470</td>\n",
       "      <td>0.529953</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>0.520854</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>SVM linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.490</td>\n",
       "      <td>0.510051</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.500126</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.490</td>\n",
       "      <td>0.510051</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.510126</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Error_Rate       AUC  Precision  Average_Precision    Recall  \\\n",
       "Category                                                                 \n",
       "0              0.500  0.499650   0.494624           0.494825  0.464646   \n",
       "1              0.500  0.499650   0.504673           0.504825  0.534653   \n",
       "0              0.525  0.475898   0.474576           0.483447  0.565657   \n",
       "1              0.525  0.475898   0.475610           0.493651  0.386139   \n",
       "0              0.480  0.520552   0.513514           0.505659  0.575758   \n",
       "1              0.480  0.520552   0.528090           0.515745  0.465347   \n",
       "0              0.525  0.474397   0.465909           0.482952  0.414141   \n",
       "1              0.525  0.474397   0.482143           0.492779  0.534653   \n",
       "0              0.475  0.525303   0.518868           0.508260  0.555556   \n",
       "1              0.475  0.525303   0.531915           0.518324  0.495050   \n",
       "0              0.540  0.459646   0.451613           0.476593  0.424242   \n",
       "1              0.540  0.459646   0.467290           0.486332  0.495050   \n",
       "0              0.445  0.557006   0.535714           0.525844  0.757576   \n",
       "1              0.445  0.557006   0.600000           0.538861  0.356436   \n",
       "0              0.470  0.529953   0.525253           0.510890  0.525253   \n",
       "1              0.470  0.529953   0.534653           0.520854  0.534653   \n",
       "0              0.490  0.510051   0.504950           0.500126  0.515152   \n",
       "1              0.490  0.510051   0.515152           0.510126  0.504950   \n",
       "\n",
       "                      methods  \n",
       "Category                       \n",
       "0           Gradient Boosting  \n",
       "1           Gradient Boosting  \n",
       "0              Neural Network  \n",
       "1              Neural Network  \n",
       "0               random forest  \n",
       "1               random forest  \n",
       "0               decision tree  \n",
       "1               decision tree  \n",
       "0         logistic regression  \n",
       "1         logistic regression  \n",
       "0                         kNN  \n",
       "1                         kNN  \n",
       "0                    SVM poly  \n",
       "1                    SVM poly  \n",
       "0                  SVM linear  \n",
       "1                  SVM linear  \n",
       "0                 Naive Bayes  \n",
       "1                 Naive Bayes  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_random_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lets us look at which classes do better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lucem_illud_2020.plotConfusionMatrix(clf, dfTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The greater the area under the curve the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lucem_illud_2020.plotMultiROC(clf, dfTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the regions the classifer identifies as one class or the other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lucem_illud_2020.plotregions(clf, dfTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we do the same for real data\n",
    "\n",
    "Available data sets include:\n",
    "+ Reddit threads \"classified\" by thread topic\n",
    "+ 20 newsgroups \"classified\" by group topic\n",
    "+ Senate press releases \"classified\" by Senator (2 senators)\n",
    "+ Senate press releases \"classified\" by Senator (5 senators)\n",
    "+ Emails classified as Spam or Ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Spam\n",
      "Loading Ham\n",
      "Converting to vectors\n"
     ]
    }
   ],
   "source": [
    "#dfTrain, dfTest = lucem_illud_2020.trainTestSplit(lucem_illud_2020.loadReddit())\n",
    "#dfTrain, dfTest = lucem_illud_2020.trainTestSplit(lucem_illud_2020.loadNewsGroups())\n",
    "#dfTrain, dfTest = lucem_illud_2020.trainTestSplit(lucem_illud_2020.loadSenateSmall())\n",
    "#dfTrain, dfTest = lucem_illud_2020.trainTestSplit(lucem_illud_2020.loadSenateLarge())\n",
    "dfTrain, dfTest = lucem_illud_2020.trainTestSplit(lucem_illud_2020.loadSpam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayes\n",
    "clf = sklearn.naive_bayes.GaussianNB()\n",
    "\n",
    "#Analogizes\n",
    "#clf = sklearn.svm.SVC(kernel = 'linear', probability = True) #slow, set probability = False to speed up, but lose ROC\n",
    "#clf = sklearn.svm.SVC(kernel = 'poly', degree = 3, probability = True) #slower\n",
    "#clf = sklearn.neighbors.KNeighborsClassifier(5, weights='distance')# k, 'distance' or 'uniform'\n",
    "\n",
    "#Classical Regression\n",
    "#clf = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "#Symbolists\n",
    "#clf = sklearn.tree.DecisionTreeClassifier()\n",
    "#clf = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "#Connectionists\n",
    "#clf = sklearn.neural_network.MLPClassifier()\n",
    "\n",
    "#Ensemble\n",
    "#clf = sklearn.ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(np.stack(dfTrain['vect'], axis=0), dfTrain['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.16129</td>\n",
       "      <td>0.841723</td>\n",
       "      <td>0.779874</td>\n",
       "      <td>0.730209</td>\n",
       "      <td>0.861111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.16129</td>\n",
       "      <td>0.841723</td>\n",
       "      <td>0.890110</td>\n",
       "      <td>0.834608</td>\n",
       "      <td>0.822335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Error_Rate       AUC  Precision  Average_Precision    Recall\n",
       "Category                                                              \n",
       "Obama        0.16129  0.841723   0.779874           0.730209  0.861111\n",
       "Clinton      0.16129  0.841723   0.890110           0.834608  0.822335"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lucem_illud_2020.evaluateClassifier(clf, dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd0=lucem_illud_2020.evaluateClassifier(clf, dfTest)\n",
    "pd0['methods']='SVM linear'\n",
    "pd_reddit=pandas.concat([pd0,pd_reddit])\n",
    "#pd_senate_large=pandas.concat([pd0,pd_senate_large])\n",
    "#pd_reddit=pandas.concat([pd0,pd_random_sample])\n",
    "pd_reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>methods</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.095745</td>\n",
       "      <td>0.843973</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.679539</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.095745</td>\n",
       "      <td>0.855629</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.669281</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.068085</td>\n",
       "      <td>0.905430</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.805479</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.097872</td>\n",
       "      <td>0.909954</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.716908</td>\n",
       "      <td>0.926230</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.065957</td>\n",
       "      <td>0.891478</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.774411</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.068085</td>\n",
       "      <td>0.913082</td>\n",
       "      <td>0.831858</td>\n",
       "      <td>0.758451</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.036170</td>\n",
       "      <td>0.941742</td>\n",
       "      <td>0.974790</td>\n",
       "      <td>0.899600</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.938265</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.800413</td>\n",
       "      <td>0.942623</td>\n",
       "      <td>Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.798188</td>\n",
       "      <td>0.768421</td>\n",
       "      <td>0.586209</td>\n",
       "      <td>0.657658</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.087234</td>\n",
       "      <td>0.864434</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.694896</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.903167</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.758457</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.087234</td>\n",
       "      <td>0.906491</td>\n",
       "      <td>0.795620</td>\n",
       "      <td>0.738501</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.155319</td>\n",
       "      <td>0.764524</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.516568</td>\n",
       "      <td>0.612613</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.121277</td>\n",
       "      <td>0.835805</td>\n",
       "      <td>0.723214</td>\n",
       "      <td>0.602799</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.104255</td>\n",
       "      <td>0.849548</td>\n",
       "      <td>0.858407</td>\n",
       "      <td>0.710717</td>\n",
       "      <td>0.746154</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.151064</td>\n",
       "      <td>0.836772</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.595440</td>\n",
       "      <td>0.811475</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.072340</td>\n",
       "      <td>0.868629</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.755992</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.061702</td>\n",
       "      <td>0.913918</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.778230</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.958937</td>\n",
       "      <td>0.945736</td>\n",
       "      <td>0.904559</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.051064</td>\n",
       "      <td>0.960194</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.835472</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.374468</td>\n",
       "      <td>0.565058</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.266287</td>\n",
       "      <td>0.450450</td>\n",
       "      <td>kNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.221277</td>\n",
       "      <td>0.540383</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.263773</td>\n",
       "      <td>0.102804</td>\n",
       "      <td>kNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.242553</td>\n",
       "      <td>0.561538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.365630</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>kNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.493617</td>\n",
       "      <td>0.554880</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.283654</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>kNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.236170</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.236170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SVM poly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.772340</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.227660</td>\n",
       "      <td>0.227660</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SVM poly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SVM poly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.259574</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SVM poly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.080851</td>\n",
       "      <td>0.863058</td>\n",
       "      <td>0.884211</td>\n",
       "      <td>0.726579</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>SVM linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.070213</td>\n",
       "      <td>0.908409</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>0.751500</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>SVM linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.036170</td>\n",
       "      <td>0.946493</td>\n",
       "      <td>0.959350</td>\n",
       "      <td>0.896326</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>SVM linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.055319</td>\n",
       "      <td>0.951997</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.823733</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>SVM linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.123404</td>\n",
       "      <td>0.844538</td>\n",
       "      <td>0.719008</td>\n",
       "      <td>0.614611</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.805309</td>\n",
       "      <td>0.737374</td>\n",
       "      <td>0.575408</td>\n",
       "      <td>0.682243</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.076596</td>\n",
       "      <td>0.906674</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.780284</td>\n",
       "      <td>0.869231</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.911650</td>\n",
       "      <td>0.889831</td>\n",
       "      <td>0.802008</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Error_Rate       AUC  Precision  Average_Precision  \\\n",
       "Category                                                                    \n",
       "comp.sys.mac.hardware    0.095745  0.843973   0.843750           0.679539   \n",
       "misc.forsale             0.095745  0.855629   0.803922           0.669281   \n",
       "comp.windows.x           0.068085  0.905430   0.901639           0.805479   \n",
       "rec.autos                0.097872  0.909954   0.753333           0.716908   \n",
       "comp.sys.mac.hardware    0.065957  0.891478   0.900000           0.774411   \n",
       "misc.forsale             0.068085  0.913082   0.831858           0.758451   \n",
       "comp.windows.x           0.036170  0.941742   0.974790           0.899600   \n",
       "rec.autos                0.063830  0.938265   0.833333           0.800413   \n",
       "comp.sys.mac.hardware    0.127660  0.798188   0.768421           0.586209   \n",
       "misc.forsale             0.087234  0.864434   0.830000           0.694896   \n",
       "comp.windows.x           0.085106  0.903167   0.826087           0.758457   \n",
       "rec.autos                0.087234  0.906491   0.795620           0.738501   \n",
       "comp.sys.mac.hardware    0.155319  0.764524   0.693878           0.516568   \n",
       "misc.forsale             0.121277  0.835805   0.723214           0.602799   \n",
       "comp.windows.x           0.104255  0.849548   0.858407           0.710717   \n",
       "rec.autos                0.151064  0.836772   0.673469           0.595440   \n",
       "comp.sys.mac.hardware    0.072340  0.868629   0.923077           0.755992   \n",
       "misc.forsale             0.061702  0.913918   0.861111           0.778230   \n",
       "comp.windows.x           0.031915  0.958937   0.945736           0.904559   \n",
       "rec.autos                0.051064  0.960194   0.845070           0.835472   \n",
       "comp.sys.mac.hardware    0.374468  0.565058   0.303030           0.266287   \n",
       "misc.forsale             0.221277  0.540383   0.578947           0.263773   \n",
       "comp.windows.x           0.242553  0.561538   1.000000           0.365630   \n",
       "rec.autos                0.493617  0.554880   0.296296           0.283654   \n",
       "comp.sys.mac.hardware    0.236170  0.500000   0.000000           0.236170   \n",
       "misc.forsale             0.772340  0.500000   0.227660           0.227660   \n",
       "comp.windows.x           0.276596  0.500000   0.000000           0.276596   \n",
       "rec.autos                0.259574  0.500000   0.000000           0.259574   \n",
       "comp.sys.mac.hardware    0.080851  0.863058   0.884211           0.726579   \n",
       "misc.forsale             0.070213  0.908409   0.830357           0.751500   \n",
       "comp.windows.x           0.036170  0.946493   0.959350           0.896326   \n",
       "rec.autos                0.055319  0.951997   0.842857           0.823733   \n",
       "comp.sys.mac.hardware    0.123404  0.844538   0.719008           0.614611   \n",
       "misc.forsale             0.127660  0.805309   0.737374           0.575408   \n",
       "comp.windows.x           0.076596  0.906674   0.856061           0.780284   \n",
       "rec.autos                0.063830  0.911650   0.889831           0.802008   \n",
       "\n",
       "                         Recall              methods  \n",
       "Category                                              \n",
       "comp.sys.mac.hardware  0.729730    Gradient Boosting  \n",
       "misc.forsale           0.766355    Gradient Boosting  \n",
       "comp.windows.x         0.846154    Gradient Boosting  \n",
       "rec.autos              0.926230    Gradient Boosting  \n",
       "comp.sys.mac.hardware  0.810811       Neural Network  \n",
       "misc.forsale           0.878505       Neural Network  \n",
       "comp.windows.x         0.892308       Neural Network  \n",
       "rec.autos              0.942623       Neural Network  \n",
       "comp.sys.mac.hardware  0.657658        Random Forest  \n",
       "misc.forsale           0.775701        Random Forest  \n",
       "comp.windows.x         0.876923        Random Forest  \n",
       "rec.autos              0.893443        Random Forest  \n",
       "comp.sys.mac.hardware  0.612613        Decision Tree  \n",
       "misc.forsale           0.757009        Decision Tree  \n",
       "comp.windows.x         0.746154        Decision Tree  \n",
       "rec.autos              0.811475        Decision Tree  \n",
       "comp.sys.mac.hardware  0.756757  Logistic Regression  \n",
       "misc.forsale           0.869159  Logistic Regression  \n",
       "comp.windows.x         0.938462  Logistic Regression  \n",
       "rec.autos              0.983607  Logistic Regression  \n",
       "comp.sys.mac.hardware  0.450450                  kNN  \n",
       "misc.forsale           0.102804                  kNN  \n",
       "comp.windows.x         0.123077                  kNN  \n",
       "rec.autos              0.655738                  kNN  \n",
       "comp.sys.mac.hardware  0.000000             SVM poly  \n",
       "misc.forsale           1.000000             SVM poly  \n",
       "comp.windows.x         0.000000             SVM poly  \n",
       "rec.autos              0.000000             SVM poly  \n",
       "comp.sys.mac.hardware  0.756757           SVM linear  \n",
       "misc.forsale           0.869159           SVM linear  \n",
       "comp.windows.x         0.907692           SVM linear  \n",
       "rec.autos              0.967213           SVM linear  \n",
       "comp.sys.mac.hardware  0.783784          Naive Bayes  \n",
       "misc.forsale           0.682243          Naive Bayes  \n",
       "comp.windows.x         0.869231          Naive Bayes  \n",
       "rec.autos              0.860656          Naive Bayes  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_newsgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>methods</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.993990</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>0.989092</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.993990</td>\n",
       "      <td>0.994924</td>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.994924</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.049853</td>\n",
       "      <td>0.952182</td>\n",
       "      <td>0.920530</td>\n",
       "      <td>0.903230</td>\n",
       "      <td>0.965278</td>\n",
       "      <td>Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.049853</td>\n",
       "      <td>0.952182</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.949564</td>\n",
       "      <td>0.939086</td>\n",
       "      <td>Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.017595</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975929</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.017595</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.970443</td>\n",
       "      <td>0.970443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.008798</td>\n",
       "      <td>0.991452</td>\n",
       "      <td>0.986207</td>\n",
       "      <td>0.982291</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.008798</td>\n",
       "      <td>0.991452</td>\n",
       "      <td>0.994898</td>\n",
       "      <td>0.990663</td>\n",
       "      <td>0.989848</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.020528</td>\n",
       "      <td>0.975694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971917</td>\n",
       "      <td>0.951389</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.020528</td>\n",
       "      <td>0.975694</td>\n",
       "      <td>0.965686</td>\n",
       "      <td>0.965686</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.841723</td>\n",
       "      <td>0.779874</td>\n",
       "      <td>0.730209</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>kNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.841723</td>\n",
       "      <td>0.890110</td>\n",
       "      <td>0.834608</td>\n",
       "      <td>0.822335</td>\n",
       "      <td>kNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.422287</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.422287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SVM poly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.422287</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.577713</td>\n",
       "      <td>0.577713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SVM poly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.008798</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987964</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>SVM linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.008798</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SVM linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.190616</td>\n",
       "      <td>0.803264</td>\n",
       "      <td>0.780142</td>\n",
       "      <td>0.695648</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.190616</td>\n",
       "      <td>0.803264</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.790300</td>\n",
       "      <td>0.842640</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Error_Rate       AUC  Precision  Average_Precision    Recall  \\\n",
       "Category                                                                 \n",
       "Obama       0.005865  0.993990   0.993056           0.989092  0.993056   \n",
       "Clinton     0.005865  0.993990   0.994924           0.992806  0.994924   \n",
       "Obama       0.049853  0.952182   0.920530           0.903230  0.965278   \n",
       "Clinton     0.049853  0.952182   0.973684           0.949564  0.939086   \n",
       "Obama       0.017595  0.979167   1.000000           0.975929  0.958333   \n",
       "Clinton     0.017595  0.979167   0.970443           0.970443  1.000000   \n",
       "Obama       0.008798  0.991452   0.986207           0.982291  0.993056   \n",
       "Clinton     0.008798  0.991452   0.994898           0.990663  0.989848   \n",
       "Obama       0.020528  0.975694   1.000000           0.971917  0.951389   \n",
       "Clinton     0.020528  0.975694   0.965686           0.965686  1.000000   \n",
       "Obama       0.161290  0.841723   0.779874           0.730209  0.861111   \n",
       "Clinton     0.161290  0.841723   0.890110           0.834608  0.822335   \n",
       "Obama       0.422287  0.500000   0.000000           0.422287  0.000000   \n",
       "Clinton     0.422287  0.500000   0.577713           0.577713  1.000000   \n",
       "Obama       0.008798  0.989583   1.000000           0.987964  0.979167   \n",
       "Clinton     0.008798  0.989583   0.985000           0.985000  1.000000   \n",
       "Obama       0.190616  0.803264   0.780142           0.695648  0.763889   \n",
       "Clinton     0.190616  0.803264   0.830000           0.790300  0.842640   \n",
       "\n",
       "                      methods  \n",
       "Category                       \n",
       "Obama       Gradient Boosting  \n",
       "Clinton     Gradient Boosting  \n",
       "Obama          Neural Network  \n",
       "Clinton        Neural Network  \n",
       "Obama           Random Forest  \n",
       "Clinton         Random Forest  \n",
       "Obama           Decision Tree  \n",
       "Clinton         Decision Tree  \n",
       "Obama     Logistic Regression  \n",
       "Clinton   Logistic Regression  \n",
       "Obama                     kNN  \n",
       "Clinton                   kNN  \n",
       "Obama                SVM poly  \n",
       "Clinton              SVM poly  \n",
       "Obama              SVM linear  \n",
       "Clinton            SVM linear  \n",
       "Obama             Naive Bayes  \n",
       "Clinton           Naive Bayes  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_senate_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>methods</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kennedy</th>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.998934</td>\n",
       "      <td>0.996795</td>\n",
       "      <td>0.996795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Klobuchar</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kohl</th>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987393</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerry</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyl</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kennedy</th>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.964767</td>\n",
       "      <td>0.927052</td>\n",
       "      <td>0.916859</td>\n",
       "      <td>0.980707</td>\n",
       "      <td>Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Klobuchar</th>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.965972</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.922087</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kohl</th>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.965278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.936966</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerry</th>\n",
       "      <td>0.037179</td>\n",
       "      <td>0.948929</td>\n",
       "      <td>0.947867</td>\n",
       "      <td>0.892680</td>\n",
       "      <td>0.917431</td>\n",
       "      <td>Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyl</th>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.982437</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.963184</td>\n",
       "      <td>0.966387</td>\n",
       "      <td>Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kennedy</th>\n",
       "      <td>0.020513</td>\n",
       "      <td>0.981859</td>\n",
       "      <td>0.956656</td>\n",
       "      <td>0.953068</td>\n",
       "      <td>0.993569</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Klobuchar</th>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.957639</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.906708</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kohl</th>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.984699</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.947780</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerry</th>\n",
       "      <td>0.014103</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.990521</td>\n",
       "      <td>0.961167</td>\n",
       "      <td>0.958716</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyl</th>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.995798</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992879</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kennedy</th>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.996785</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996133</td>\n",
       "      <td>0.993569</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Klobuchar</th>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.999306</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kohl</th>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerry</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyl</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kennedy</th>\n",
       "      <td>0.058974</td>\n",
       "      <td>0.947168</td>\n",
       "      <td>0.886297</td>\n",
       "      <td>0.875323</td>\n",
       "      <td>0.977492</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Klobuchar</th>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kohl</th>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949573</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerry</th>\n",
       "      <td>0.028205</td>\n",
       "      <td>0.960772</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.918416</td>\n",
       "      <td>0.935780</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyl</th>\n",
       "      <td>0.024359</td>\n",
       "      <td>0.920168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864695</td>\n",
       "      <td>0.840336</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kennedy</th>\n",
       "      <td>0.191026</td>\n",
       "      <td>0.827611</td>\n",
       "      <td>0.697561</td>\n",
       "      <td>0.673538</td>\n",
       "      <td>0.919614</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Klobuchar</th>\n",
       "      <td>0.032051</td>\n",
       "      <td>0.890972</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>0.644893</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kohl</th>\n",
       "      <td>0.034615</td>\n",
       "      <td>0.843691</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.659518</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerry</th>\n",
       "      <td>0.142308</td>\n",
       "      <td>0.790338</td>\n",
       "      <td>0.812865</td>\n",
       "      <td>0.619577</td>\n",
       "      <td>0.637615</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyl</th>\n",
       "      <td>0.058974</td>\n",
       "      <td>0.823949</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.668541</td>\n",
       "      <td>0.655462</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kennedy</th>\n",
       "      <td>0.601282</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.398718</td>\n",
       "      <td>0.398718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SVM poly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Klobuchar</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SVM poly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kohl</th>\n",
       "      <td>0.092308</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SVM poly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerry</th>\n",
       "      <td>0.279487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SVM poly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyl</th>\n",
       "      <td>0.152564</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SVM poly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kennedy</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.983433</td>\n",
       "      <td>0.974522</td>\n",
       "      <td>0.965265</td>\n",
       "      <td>0.983923</td>\n",
       "      <td>SVM linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Klobuchar</th>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>SVM linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kohl</th>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987393</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>SVM linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerry</th>\n",
       "      <td>0.011538</td>\n",
       "      <td>0.986377</td>\n",
       "      <td>0.977169</td>\n",
       "      <td>0.964367</td>\n",
       "      <td>0.981651</td>\n",
       "      <td>SVM linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyl</th>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985757</td>\n",
       "      <td>0.983193</td>\n",
       "      <td>SVM linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kennedy</th>\n",
       "      <td>0.284615</td>\n",
       "      <td>0.752494</td>\n",
       "      <td>0.590264</td>\n",
       "      <td>0.577946</td>\n",
       "      <td>0.935691</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Klobuchar</th>\n",
       "      <td>0.039744</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.523516</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kohl</th>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.728460</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.494853</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kerry</th>\n",
       "      <td>0.161538</td>\n",
       "      <td>0.765761</td>\n",
       "      <td>0.770588</td>\n",
       "      <td>0.574598</td>\n",
       "      <td>0.600917</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyl</th>\n",
       "      <td>0.093590</td>\n",
       "      <td>0.696723</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.479037</td>\n",
       "      <td>0.394958</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Error_Rate       AUC  Precision  Average_Precision    Recall  \\\n",
       "Category                                                                  \n",
       "Kennedy      0.001282  0.998934   0.996795           0.996795  1.000000   \n",
       "Klobuchar    0.000000  1.000000   1.000000           1.000000  1.000000   \n",
       "Kohl         0.001282  0.993056   1.000000           0.987393  0.986111   \n",
       "Kerry        0.000000  1.000000   1.000000           1.000000  1.000000   \n",
       "Kyl          0.000000  1.000000   1.000000           1.000000  1.000000   \n",
       "Kennedy      0.038462  0.964767   0.927052           0.916859  0.980707   \n",
       "Klobuchar    0.006410  0.965972   0.982456           0.922087  0.933333   \n",
       "Kohl         0.006410  0.965278   1.000000           0.936966  0.930556   \n",
       "Kerry        0.037179  0.948929   0.947867           0.892680  0.917431   \n",
       "Kyl          0.006410  0.982437   0.991379           0.963184  0.966387   \n",
       "Kennedy      0.020513  0.981859   0.956656           0.953068  0.993569   \n",
       "Klobuchar    0.007692  0.957639   0.982143           0.906708  0.916667   \n",
       "Kohl         0.005128  0.984699   0.972222           0.947780  0.972222   \n",
       "Kerry        0.014103  0.977578   0.990521           0.961167  0.958716   \n",
       "Kyl          0.001282  0.995798   1.000000           0.992879  0.991597   \n",
       "Kennedy      0.002564  0.996785   1.000000           0.996133  0.993569   \n",
       "Klobuchar    0.001282  0.999306   0.983607           0.983607  1.000000   \n",
       "Kohl         0.001282  0.999294   0.986301           0.986301  1.000000   \n",
       "Kerry        0.000000  1.000000   1.000000           1.000000  1.000000   \n",
       "Kyl          0.000000  1.000000   1.000000           1.000000  1.000000   \n",
       "Kennedy      0.058974  0.947168   0.886297           0.875323  0.977492   \n",
       "Klobuchar    0.003846  0.975000   1.000000           0.953846  0.950000   \n",
       "Kohl         0.005128  0.972222   1.000000           0.949573  0.944444   \n",
       "Kerry        0.028205  0.960772   0.962264           0.918416  0.935780   \n",
       "Kyl          0.024359  0.920168   1.000000           0.864695  0.840336   \n",
       "Kennedy      0.191026  0.827611   0.697561           0.673538  0.919614   \n",
       "Klobuchar    0.032051  0.890972   0.786885           0.644893  0.800000   \n",
       "Kohl         0.034615  0.843691   0.909091           0.659518  0.694444   \n",
       "Kerry        0.142308  0.790338   0.812865           0.619577  0.637615   \n",
       "Kyl          0.058974  0.823949   0.939759           0.668541  0.655462   \n",
       "Kennedy      0.601282  0.500000   0.398718           0.398718  1.000000   \n",
       "Klobuchar    0.076923  0.500000   0.000000           0.076923  0.000000   \n",
       "Kohl         0.092308  0.500000   0.000000           0.092308  0.000000   \n",
       "Kerry        0.279487  0.500000   0.000000           0.279487  0.000000   \n",
       "Kyl          0.152564  0.500000   0.000000           0.152564  0.000000   \n",
       "Kennedy      0.016667  0.983433   0.974522           0.965265  0.983923   \n",
       "Klobuchar    0.001282  0.991667   1.000000           0.984615  0.983333   \n",
       "Kohl         0.001282  0.993056   1.000000           0.987393  0.986111   \n",
       "Kerry        0.011538  0.986377   0.977169           0.964367  0.981651   \n",
       "Kyl          0.002564  0.991597   1.000000           0.985757  0.983193   \n",
       "Kennedy      0.284615  0.752494   0.590264           0.577946  0.935691   \n",
       "Klobuchar    0.039744  0.764583   0.914286           0.523516  0.533333   \n",
       "Kohl         0.051282  0.728460   0.970588           0.494853  0.458333   \n",
       "Kerry        0.161538  0.765761   0.770588           0.574598  0.600917   \n",
       "Kyl          0.093590  0.696723   0.979167           0.479037  0.394958   \n",
       "\n",
       "                       methods  \n",
       "Category                        \n",
       "Kennedy      Gradient Boosting  \n",
       "Klobuchar    Gradient Boosting  \n",
       "Kohl         Gradient Boosting  \n",
       "Kerry        Gradient Boosting  \n",
       "Kyl          Gradient Boosting  \n",
       "Kennedy         Neural Network  \n",
       "Klobuchar       Neural Network  \n",
       "Kohl            Neural Network  \n",
       "Kerry           Neural Network  \n",
       "Kyl             Neural Network  \n",
       "Kennedy          Random Forest  \n",
       "Klobuchar        Random Forest  \n",
       "Kohl             Random Forest  \n",
       "Kerry            Random Forest  \n",
       "Kyl              Random Forest  \n",
       "Kennedy          Decision Tree  \n",
       "Klobuchar        Decision Tree  \n",
       "Kohl             Decision Tree  \n",
       "Kerry            Decision Tree  \n",
       "Kyl              Decision Tree  \n",
       "Kennedy    Logistic Regression  \n",
       "Klobuchar  Logistic Regression  \n",
       "Kohl       Logistic Regression  \n",
       "Kerry      Logistic Regression  \n",
       "Kyl        Logistic Regression  \n",
       "Kennedy                    KNN  \n",
       "Klobuchar                  KNN  \n",
       "Kohl                       KNN  \n",
       "Kerry                      KNN  \n",
       "Kyl                        KNN  \n",
       "Kennedy               SVM poly  \n",
       "Klobuchar             SVM poly  \n",
       "Kohl                  SVM poly  \n",
       "Kerry                 SVM poly  \n",
       "Kyl                   SVM poly  \n",
       "Kennedy             SVM linear  \n",
       "Klobuchar           SVM linear  \n",
       "Kohl                SVM linear  \n",
       "Kerry               SVM linear  \n",
       "Kyl                 SVM linear  \n",
       "Kennedy            Naive Bayes  \n",
       "Klobuchar          Naive Bayes  \n",
       "Kohl               Naive Bayes  \n",
       "Kerry              Naive Bayes  \n",
       "Kyl                Naive Bayes  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_senate_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>methods</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>not spam</th>\n",
       "      <td>0.112573</td>\n",
       "      <td>0.611392</td>\n",
       "      <td>0.885023</td>\n",
       "      <td>0.884974</td>\n",
       "      <td>0.998294</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.112573</td>\n",
       "      <td>0.611392</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.325840</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not spam</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.847740</td>\n",
       "      <td>0.954698</td>\n",
       "      <td>0.951856</td>\n",
       "      <td>0.970990</td>\n",
       "      <td>Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.847740</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.624005</td>\n",
       "      <td>0.724490</td>\n",
       "      <td>Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not spam</th>\n",
       "      <td>0.080409</td>\n",
       "      <td>0.778871</td>\n",
       "      <td>0.933116</td>\n",
       "      <td>0.931291</td>\n",
       "      <td>0.976109</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.080409</td>\n",
       "      <td>0.778871</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.526886</td>\n",
       "      <td>0.581633</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not spam</th>\n",
       "      <td>0.073099</td>\n",
       "      <td>0.812879</td>\n",
       "      <td>0.943709</td>\n",
       "      <td>0.941334</td>\n",
       "      <td>0.972696</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.073099</td>\n",
       "      <td>0.812879</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.572157</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not spam</th>\n",
       "      <td>0.106725</td>\n",
       "      <td>0.640297</td>\n",
       "      <td>0.892802</td>\n",
       "      <td>0.892618</td>\n",
       "      <td>0.994881</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.106725</td>\n",
       "      <td>0.640297</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.360404</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not spam</th>\n",
       "      <td>0.090643</td>\n",
       "      <td>0.721913</td>\n",
       "      <td>0.915873</td>\n",
       "      <td>0.914965</td>\n",
       "      <td>0.984642</td>\n",
       "      <td>kNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.090643</td>\n",
       "      <td>0.721913</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.460138</td>\n",
       "      <td>0.459184</td>\n",
       "      <td>kNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not spam</th>\n",
       "      <td>0.143275</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.856725</td>\n",
       "      <td>0.856725</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SVM_poly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.143275</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SVM_poly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not spam</th>\n",
       "      <td>0.071637</td>\n",
       "      <td>0.766995</td>\n",
       "      <td>0.928230</td>\n",
       "      <td>0.927742</td>\n",
       "      <td>0.993174</td>\n",
       "      <td>SVM_linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.071637</td>\n",
       "      <td>0.766995</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.568654</td>\n",
       "      <td>0.540816</td>\n",
       "      <td>SVM_linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not spam</th>\n",
       "      <td>0.134503</td>\n",
       "      <td>0.840775</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.950887</td>\n",
       "      <td>0.875427</td>\n",
       "      <td>naive_bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.134503</td>\n",
       "      <td>0.840775</td>\n",
       "      <td>0.519737</td>\n",
       "      <td>0.446749</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>naive_bayes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Error_Rate       AUC  Precision  Average_Precision    Recall  \\\n",
       "Category                                                                 \n",
       "not spam    0.112573  0.611392   0.885023           0.884974  0.998294   \n",
       "spam        0.112573  0.611392   0.956522           0.325840  0.224490   \n",
       "not spam    0.064327  0.847740   0.954698           0.951856  0.970990   \n",
       "spam        0.064327  0.847740   0.806818           0.624005  0.724490   \n",
       "not spam    0.080409  0.778871   0.933116           0.931291  0.976109   \n",
       "spam        0.080409  0.778871   0.802817           0.526886  0.581633   \n",
       "not spam    0.073099  0.812879   0.943709           0.941334  0.972696   \n",
       "spam        0.073099  0.812879   0.800000           0.572157  0.653061   \n",
       "not spam    0.106725  0.640297   0.892802           0.892618  0.994881   \n",
       "spam        0.106725  0.640297   0.903226           0.360404  0.285714   \n",
       "not spam    0.090643  0.721913   0.915873           0.914965  0.984642   \n",
       "spam        0.090643  0.721913   0.833333           0.460138  0.459184   \n",
       "not spam    0.143275  0.500000   0.856725           0.856725  1.000000   \n",
       "spam        0.143275  0.500000   0.000000           0.143275  0.000000   \n",
       "not spam    0.071637  0.766995   0.928230           0.927742  0.993174   \n",
       "spam        0.071637  0.766995   0.929825           0.568654  0.540816   \n",
       "not spam    0.134503  0.840775   0.964286           0.950887  0.875427   \n",
       "spam        0.134503  0.840775   0.519737           0.446749  0.806122   \n",
       "\n",
       "                      methods  \n",
       "Category                       \n",
       "not spam    Gradient Boosting  \n",
       "spam        Gradient Boosting  \n",
       "not spam       Neural Network  \n",
       "spam           Neural Network  \n",
       "not spam        Random Forest  \n",
       "spam            Random Forest  \n",
       "not spam        Decision Tree  \n",
       "spam            Decision Tree  \n",
       "not spam  Logistic Regression  \n",
       "spam      Logistic Regression  \n",
       "not spam                  kNN  \n",
       "spam                      kNN  \n",
       "not spam             SVM_poly  \n",
       "spam                 SVM_poly  \n",
       "not spam           SVM_linear  \n",
       "spam               SVM_linear  \n",
       "not spam          naive_bayes  \n",
       "spam              naive_bayes  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucem_illud_2020.plotConfusionMatrix(clf, dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucem_illud_2020.plotMultiROC(clf, dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucem_illud_2020.plotregions(clf, dfTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 1*</span>\n",
    "\n",
    "<span style=\"color:red\">Go back through all of the cells above and generate 10 distinct artificial datasets and classify them with all of the available methods. Add a cell immediately below and describe which classifier(s) worked best with which artificially constructed data source and why. Then go through all of the empirical datasets (i.e., Newsgroups, Senate Small, Senate Large, Email Spam) and classify them with all available methods. Add a second cell immediately below and describe which classifier(s) worked best with which data set and why.\n",
    "\n",
    "<span style=\"color:red\">***Stretch*** (but also required) Wander through the SKLearn documentation available [here](http://scikit-learn.org/stable/), particularly perusing the classifiers. In cells following, identify and implement a new classifier that we have not yet used (e.g., AdaBoost, CART) on one artificial dataset and one real dataset (used above). Then, in the next cell describe the classifier, detail how it compares with the approaches above, and why it performed better or worse than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinton / Obama Press Releases\n",
    "\n",
    "We often will not have nicely prepared data, so we will work though the proccess of cleaning and structuring in more detail here:\n",
    "\n",
    "While the Clinton and Obama Senatorial Press Releases are not hand-coded, we can imagine that we have been given a stack of such press releases, but lost the metadata associated with which senatorial office issued which. If we label a few of them, how well can our classifier do at recovering the rest? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObamaClintonReleases = pandas.read_csv('../data/ObamaClintonReleases.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn the 'targetSenator' column into a binary category variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObamaClintonReleases['category'] = [s == 'Obama' for s in ObamaClintonReleases['targetSenator']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObamaClintonReleases['tokenized_text'] = ObamaClintonReleases['text'].apply(lambda x: lucem_illud_2020.word_tokenize(x))\n",
    "ObamaClintonReleases['normalized_text'] = ObamaClintonReleases['tokenized_text'].apply(lambda x: lucem_illud_2020.normalizeTokens(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into training data and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdBackFraction = .2\n",
    "train_data_df, test_data_df = lucem_illud_2020.trainTestSplit(ObamaClintonReleases, holdBackFraction=holdBackFraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data_df))\n",
    "print(len(test_data_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try with a logistic regression, which may be familiar to you from statistical methods classes. First, we must turn the training dataset into a tf-idf matrix (`lucem_illud_2020.generateVecs()` will help with this but for now we are doing it the long way):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=100, min_df=2, stop_words='english', norm='l2')\n",
    "TFVects = TFVectorizer.fit_transform(train_data_df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can use the CountVectorizer instead, which simply produces a matrix of word counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TFVects.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save this in the dataframe to make things easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df['vect'] = [np.array(v).flatten() for v in TFVects.todense()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a regression, we cannot have more variables than cases. So, we need to first do a dimension reduction. First, we will approah this with PCA. You have previously seen this in week 3. Here we are not concerned about visualization, but rather classification and so all principal components are calculated. Watch out: we have to use `stack` not `sum` for combining the vectors. We note that you could also use topic loading and embedding dimensions as featured variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sklearn.decomposition.PCA()\n",
    "reduced_data = pca.fit_transform(np.stack(train_data_df['vect'], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can store the PCA space vectors in the dataframe too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df['pca'] = [r for r in reduced_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization in 2D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "ax.axis('off')\n",
    "pallet = seaborn.color_palette(palette='coolwarm', n_colors = 2)\n",
    "\n",
    "#Plot Obama\n",
    "a = np.stack(train_data_df[train_data_df['category']]['pca'])\n",
    "ax.scatter(a[:,0], a[:, 1], c = pallet[0], label = \"True\")\n",
    "\n",
    "#Plot not Obama\n",
    "a = np.stack(train_data_df[train_data_df['category'].eq(False)]['pca'])\n",
    "ax.scatter(a[:,0], a[:, 1], c = pallet[1], label = \"False\")\n",
    "    \n",
    "ax.legend(loc = 'upper right', title = 'Is Obama')\n",
    "plt.title('True Classes, Training Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA cannot distinguish Obama very well. Let's perform a screeplot to see how many Principal Components we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(train_data_df)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize = (16, 5), sharey=True)\n",
    "\n",
    "eigen_vals = np.arange(n) + 1\n",
    "ax1.plot(eigen_vals, pca.explained_variance_ratio_, 'ro-', linewidth=1)\n",
    "ax1.set_title('Scree Plot (Full)')\n",
    "ax1.set_xlabel('Principal Component')\n",
    "ax1.set_ylabel('Proportion of Explained Variance')\n",
    "\n",
    "eigen_vals = np.arange(50) + 1\n",
    "ax2.plot(eigen_vals, pca.explained_variance_ratio_[:50], 'ro-', linewidth=1)\n",
    "ax2.set_title('Scree Plot (First 50 Principal Components)')\n",
    "ax2.set_xlabel('Principal Component')\n",
    "ax2.set_ylabel('Proportion of Explained Variance')\n",
    "\n",
    "\n",
    "eigen_vals = np.arange(20) + 1\n",
    "ax3.plot(eigen_vals, pca.explained_variance_ratio_[:20], 'ro-', linewidth=2)\n",
    "ax3.set_title('Scree Plot (First 50 Principal Components)')\n",
    "ax3.set_xlabel('Principal Component')\n",
    "ax3.set_ylabel('Proportion of Explained Variance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose the first 10 pricipal components as our covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df['pca_reduced_10'] = train_data_df['pca'].apply(lambda x: x[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit a logistic regression to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = sklearn.linear_model.LogisticRegression()\n",
    "logistic.fit(np.stack(train_data_df['pca_reduced_10'], axis=0), train_data_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the logistic regression performs on the training dataset from which we develop the model. Unfortunately, the mean accuracy is only about 64%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic.score(np.stack(train_data_df['pca_reduced_10'], axis=0), train_data_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does it perform on the testing dataset, which we \"held out\" and did not use for model training? We need to repeat all the steps on the testing data, but without retraining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create vectors\n",
    "TFVects_test = TFVectorizer.transform(test_data_df['text'])\n",
    "test_data_df['vect'] = [np.array(v).flatten() for v in TFVects_test.todense()]\n",
    "\n",
    "#PCA\n",
    "reduced_data_test = pca.transform(np.stack(test_data_df['vect'], axis=0))\n",
    "test_data_df['pca'] = [r for r in reduced_data_test]\n",
    "test_data_df['pca_reduced_10'] = test_data_df['pca'].apply(lambda x: x[:10])\n",
    "\n",
    "#Test\n",
    "logistic.score(np.stack(test_data_df['pca_reduced_10'], axis=0), test_data_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly poorer. How about using more dimensions (40)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df['pca_reduced_40'] = train_data_df['pca'].apply(lambda x: x[:40])\n",
    "test_data_df['pca_reduced_40'] = test_data_df['pca'].apply(lambda x: x[:40])\n",
    "\n",
    "logistic.fit(np.stack(train_data_df['pca_reduced_40'], axis=0), train_data_df['category'])\n",
    "\n",
    "print(\"Training:\")\n",
    "print(logistic.score(np.stack(train_data_df['pca_reduced_40'], axis=0), train_data_df['category']))\n",
    "print(\"Testing:\")\n",
    "print(logistic.score(np.stack(test_data_df['pca_reduced_40'], axis=0), test_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or still more (100)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df['pca_reduced_100'] = train_data_df['pca'].apply(lambda x: x[:100])\n",
    "test_data_df['pca_reduced_100'] = test_data_df['pca'].apply(lambda x: x[:100])\n",
    "\n",
    "logistic.fit(np.stack(train_data_df['pca_reduced_100'], axis=0), train_data_df['category'])\n",
    "\n",
    "print(\"Training:\")\n",
    "print(logistic.score(np.stack(train_data_df['pca_reduced_100'], axis=0), train_data_df['category']))\n",
    "print(\"Testing:\")\n",
    "print(logistic.score(np.stack(test_data_df['pca_reduced_100'], axis=0), test_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or even more (200)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df['pca_reduced_200'] = train_data_df['pca'].apply(lambda x: x[:200])\n",
    "test_data_df['pca_reduced_200'] = test_data_df['pca'].apply(lambda x: x[:200])\n",
    "\n",
    "logistic.fit(np.stack(train_data_df['pca_reduced_200'], axis=0), train_data_df['category'])\n",
    "\n",
    "print(\"Training:\")\n",
    "print(logistic.score(np.stack(train_data_df['pca_reduced_200'], axis=0), train_data_df['category']))\n",
    "print(\"Testing:\")\n",
    "print(logistic.score(np.stack(test_data_df['pca_reduced_200'], axis=0), test_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is becoming ridiculous (400)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df['pca_reduced_400'] = train_data_df['pca'].apply(lambda x: x[:400])\n",
    "test_data_df['pca_reduced_400'] = test_data_df['pca'].apply(lambda x: x[:400])\n",
    "\n",
    "logistic.fit(np.stack(train_data_df['pca_reduced_400'], axis=0), train_data_df['category'])\n",
    "\n",
    "print(\"Training:\")\n",
    "print(logistic.score(np.stack(train_data_df['pca_reduced_400'], axis=0), train_data_df['category']))\n",
    "print(\"Testing:\")\n",
    "print(logistic.score(np.stack(test_data_df['pca_reduced_400'], axis=0), test_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the number of covariates would overfit our data, and it seems that using a logistic regression, our prediction accuracy is at best about 65%. We can, however, try a logistic regression that uses the TF-IDF scores for each word, but with an L1 regularization or L1-norm loss function, which is also known as least absolute deviations (LAD), least absolute errors (LAE) or L1 penalty. It minimizes the sum of the absolute differences (S) between the target value ($Y_i$) and the estimated values ($f(x_i)$) and prunes all insignificant variables (i.e., word TF-IDF scores):\n",
    "\n",
    "$S=\\sum^n_{i=1}|y_i=f(x_i)|$\n",
    "\n",
    "The result is a model retaining only the most individually significant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_l1= sklearn.linear_model.LogisticRegression(penalty='l2')\n",
    "logistic_l1.fit(np.stack(train_data_df['vect'], axis=0), train_data_df['category'])\n",
    "print(logistic_l1.score(np.stack(train_data_df['vect'], axis=0), train_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using training data, and then test it on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logistic_l1.score(np.stack(test_data_df['vect'], axis=0), test_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "81% accuracy seems like the best we can get by using a logistic regression.\n",
    "\n",
    "Now let's try with Naive Bayes. Classically, it is trained with word counts, but TF-IDF vectors are also quite good:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveBayes = sklearn.naive_bayes.BernoulliNB()\n",
    "naiveBayes.fit(np.stack(train_data_df['vect'], axis=0), train_data_df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training:\")\n",
    "print(naiveBayes.score(np.stack(train_data_df['vect'], axis=0), train_data_df['category']))\n",
    "print(\"Testing:\")\n",
    "print(naiveBayes.score(np.stack(test_data_df['vect'], axis=0), test_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit better than the logit, but that's just looking at the accuracy. What about other measures? Let's first save the predictions in the dataframe to save use rerunning the model every time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_df['nb_predict'] = naiveBayes.predict(np.stack(test_data_df['vect'], axis=0))\n",
    "test_data_df['nb_predict_prob_true'] = naiveBayes.predict_proba(np.stack(test_data_df['vect'], axis=0))[:,0] #other is prop false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.precision_score(test_data_df['category'], test_data_df['nb_predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.recall_score(test_data_df['category'], test_data_df['nb_predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.f1_score(test_data_df['category'], test_data_df['nb_predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how well our posterior distribution looks relative to the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.grid(False)\n",
    "ax.set_frame_on(False)\n",
    "test_data_df[test_data_df['category'].eq(True)]['nb_predict_prob_true'].hist(alpha = 0.5, ax = ax, bins = 10, label = 'True', color = 'red')\n",
    "test_data_df[test_data_df['category'].eq(False)]['nb_predict_prob_true'].hist(alpha = 0.5, ax = ax, bins = 10, label = 'False', color = 'blue')\n",
    "ax.set_xlim((0,1.1))\n",
    "ax.legend(title = \"Is Obama\")\n",
    "ax.set_xlabel('posterior')\n",
    "ax.set_ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification is suprisingly accurate. We can even look at what words are most influential with a bit of simple math:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top indices\n",
    "trueVals, falseVals = naiveBayes.feature_log_prob_\n",
    "\n",
    "words_dict = {\n",
    "    'Obama' : [],\n",
    "    'Obama_log_prob' : [],\n",
    "    'Clinton' : [],\n",
    "    'Clinton_log_prob' : [],\n",
    "}\n",
    "\n",
    "for i, prob in sorted(enumerate(trueVals), key = lambda x:x[1], reverse=True)[:15]:\n",
    "    words_dict['Obama'].append(TFVectorizer.get_feature_names()[i])\n",
    "    words_dict['Obama_log_prob'].append(prob)\n",
    "\n",
    "for i, prob in sorted(enumerate(falseVals), key = lambda x:x[1], reverse=True)[:15]:\n",
    "    words_dict['Clinton'].append(TFVectorizer.get_feature_names()[i])\n",
    "    words_dict['Clinton_log_prob'].append(prob)\n",
    "    \n",
    "pandas.DataFrame(words_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to classify our text into one of *many* classes? The multinomial Naive Bayes generating model assumes that document features (e.g., words) are generated by draws from a multinomial distribution (recall this gives the probability to observe a particular pattern of counts across features). \n",
    "\n",
    "Let's use again the dataset we used in week 3, the 20 newsgroup dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = sklearn.datasets.fetch_20newsgroups(data_home = '../data') #Free data to play with: documents from a newsgroup corpus.\n",
    "newsgroups.target_names #Possible categories, i.e., the newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pick specific categories, and pull the relevant training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_categories = ['talk.religion.misc', 'soc.religion.christian', 'sci.space', 'comp.graphics'] #Can change these of course\n",
    "\n",
    "newsgroupsDF = pandas.DataFrame(columns = ['text', 'category', 'source_file'])\n",
    "for category in target_categories:\n",
    "    print(\"Loading data for: {}\".format(category))\n",
    "    ng = sklearn.datasets.fetch_20newsgroups(categories = [category], remove=['headers', 'footers', 'quotes'], data_home = '../data')\n",
    "    newsgroupsDF = newsgroupsDF.append(pandas.DataFrame({'text' : ng.data, 'category' : [category] * len(ng.data), 'source_file' : ng.filenames}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to tokenize, and make a training and testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroupsDF['tokenized_text'] = newsgroupsDF['text'].apply(lambda x: lucem_illud_2020.word_tokenize(x))\n",
    "newsgroupsDF['normalized_text'] = newsgroupsDF['tokenized_text'].apply(lambda x: lucem_illud_2020.normalizeTokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdBackFraction = .2\n",
    "train_ng_df, test_ng_df = lucem_illud_2020.trainTestSplit(newsgroupsDF, holdBackFraction=holdBackFraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_ng_df))\n",
    "print(len(test_ng_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to extract features from the text. We can use built-in feature extraction to do so. We will use a tf-idf vectorizer, which converts the document into a vector of words with tf-idf weights (term-frequency inverse-document frequency). This gives high weight to words that show up a lot in a given document, but rarely across documents in the corpus (more distinctive). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFVectorizer_ng = sklearn.feature_extraction.text.TfidfVectorizer(max_df=100, min_df=2, stop_words='english', norm='l2')\n",
    "TFVects_ng = TFVectorizer_ng.fit_transform(train_ng_df['text'])\n",
    "train_ng_df['vect'] = [np.array(v).flatten() for v in TFVects_ng.todense()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultinomialNB_ng = sklearn.naive_bayes.MultinomialNB()\n",
    "MultinomialNB_ng.fit(np.stack(train_ng_df['vect'], axis = 0), train_ng_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and save predictions to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ng_df['nb_predict'] = MultinomialNB_ng.predict(np.stack(train_ng_df['vect'], axis=0))\n",
    "print(\"Training score:\")\n",
    "print(MultinomialNB_ng.score(np.stack(train_ng_df['vect'], axis=0), train_ng_df['category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ng_df[['category', 'nb_predict']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good, lets examine the testing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create vectors\n",
    "TFVects_test = TFVectorizer_ng.transform(test_ng_df['text'])\n",
    "test_ng_df['vect'] = [np.array(v).flatten() for v in TFVects_test.todense()]\n",
    "\n",
    "#Add to df\n",
    "test_ng_df['nb_predict'] = MultinomialNB_ng.predict(np.stack(test_ng_df['vect'], axis=0))\n",
    "\n",
    "#Test\n",
    "print(\"Testing score:\")\n",
    "print(MultinomialNB_ng.score(np.stack(test_ng_df['vect'], axis=0), test_ng_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even use a confusion matrix, like we used last week for evaluating human coders relative to one another. Now we are evaluating our classifier relative to human coding. We'll just use the one in `lucem_illud_2020`, which requres a classifier and a dataframe with `'vect'` and `'category'` columns, like we have in the examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucem_illud_2020.plotConfusionMatrix(MultinomialNB_ng, test_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the precision, recall, and F-measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.precision_score(test_ng_df['category'], test_ng_df['nb_predict'], average = 'weighted')) #precision\n",
    "print(sklearn.metrics.recall_score(test_ng_df['category'], test_ng_df['nb_predict'], average = 'weighted')) #recall\n",
    "print(sklearn.metrics.f1_scoretest_ng_df['category'], test_ng_df['nb_predict'], average = 'weighted')) #F-1 measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate these per catagory. This has the same requiments as `plotConfusionMatrix`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucem_illud_2020.metrics.evaluateClassifier(MultinomialNB_ng, test_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the ROC curves. This has the same requiments as `plotConfusionMatrix`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucem_illud_2020.plotMultiROC(MultinomialNB_ng, test_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can plot the PCA space visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucem_illud_2020.plotregions(MultinomialNB_ng, test_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 2*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform Logistic and Na√Øve Bayes classification (binary or multinomial) using training, testing and extrapolation (uncoded) data from texts and hand-classifications associated with your final project (e.g., these could be crowd-sourced codes gathered through Amazon Mechanical Turk last week). Visualize the confusion matrix for training and testing sets. Calculate precision, recall, the F-measure, and AUC, then perform an ROC visualization. How do these classifiers perform? Exrapolate codes from these models to all uncoded data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees can be used to predict both categorical/class labels (i.e., classification) and continuous labels (i.e., regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs_df = lucem_illud_2020.multiBlobs(noise=.2, centers=[(0,0), (0,5), (5,0), (-5,0), (0,-5)])\n",
    "df_exampleTree_train, df_exampleTree_test = lucem_illud_2020.trainTestSplit(blobs_df)\n",
    "lucem_illud_2020.plotter(df_exampleTree_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import our Decision Tree classifier from sklearn.tree (familiar syntax) and fit it using the fit method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree = sklearn.tree.DecisionTreeClassifier(max_depth=4,random_state=0)\n",
    "clf_tree.fit(np.stack(df_exampleTree_train['vect'], axis =0), df_exampleTree_train['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what's going on visually with the classification: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucem_illud_2020.plotregions(clf_tree, df_exampleTree_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucem_illud_2020.evaluateClassifier(clf_tree, df_exampleTree_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(df_exampleTree_test['category'],clf_tree.predict(np.stack(df_exampleTree_test['vect'], axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we trim the tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depthvec = []\n",
    "scorevec = []\n",
    "for i in range(1,20):\n",
    "    tree2 = sklearn.tree.DecisionTreeClassifier(max_depth=i,random_state=0)\n",
    "    tree2.fit(np.stack(df_exampleTree_train['vect'], axis =0), df_exampleTree_train['category'])\n",
    "    score = sklearn.metrics.accuracy_score(df_exampleTree_test['category'], tree2.predict(np.stack(df_exampleTree_test['vect'], axis = 0)))\n",
    "    depthvec.append(i)\n",
    "    scorevec.append(score)\n",
    "plt.scatter(depthvec,scorevec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select different layers of the decision tree or \"prune\" it. At approximately four layers down in the decision tree, the shape is somewhat odd, suggesting that our model is overfitting beyond those four layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining multiple overfitting estimators turns out to be a key idea in machine learning. This is called **bagging** and is a type of **ensemble** method. The idea is to make many randomized estimators--each can overfit, as decision trees are wont to do--but then to combine them, ultimately producing a better classification. A **random forest** is produced by bagging decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = sklearn.tree.DecisionTreeClassifier(max_depth=10) #Create an instance of our decision tree classifier.\n",
    "\n",
    "bag = sklearn.ensemble.BaggingClassifier(tree, n_estimators=100, max_samples=0.8, random_state=1) #Each tree uses up to 80% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag.fit(np.stack(df_exampleTree_train['vect'], axis =0), df_exampleTree_train['category']) #Fit the bagged classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucem_illud_2020.plotregions(bag, df_exampleTree_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucem_illud_2020.evaluateClassifier(bag, df_exampleTree_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucem_illud_2020.plotConfusionMatrix(bag, df_exampleTree_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 3*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform decision tree and random forest classification (binary, multinomial or continuous) using training, testing and extrapolation (uncoded) data from texts and hand-classifications associated with your final project. As with ***Exercise 2***, these could be crowd-sourced codes gathered through Amazon Mechanical Turk last week. Visualize the classification of data points. Calculate relevant metrics (e.g., precision, recall, the F-measure, and AUC). Now build an ensemble classifier by bagging trees into a random forest. Visualize the result. How do these classifiers perform? What does ensemble learning do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-Nearest neighbors classifier takes a simpler premise than those before: Find the closest labeled datapoint in set and \"borrow\" its label.\n",
    "\n",
    "Let's use newsgroup data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroupsDF[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a testing and training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdBackFraction = .2\n",
    "train_ng_df, test_ng_df = lucem_illud_2020.trainTestSplit(newsgroupsDF, holdBackFraction=holdBackFraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize our k-nearest neighbors classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 15\n",
    "weights=\"uniform\"\n",
    "clf_knearest = sklearn.neighbors.KNeighborsClassifier(n_neighbors, weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to classify using the TF-IDF vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFVectorizer_ng = sklearn.feature_extraction.text.TfidfVectorizer(max_df=100, min_df=2, stop_words='english', norm='l2')\n",
    "TFVects_ng = TFVectorizer_ng.fit_transform(train_ng_df['text'])\n",
    "train_ng_df['vect'] = [np.array(v).flatten() for v in TFVects_ng.todense()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_knearest.fit(np.stack(train_ng_df['vect'], axis = 0), train_ng_df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucem_illud_2020.evaluateClassifier(clf_knearest, train_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lets look at the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create vectors\n",
    "TFVects_test = TFVectorizer_ng.transform(test_ng_df['text'])\n",
    "test_ng_df['vect'] = [np.array(v).flatten() for v in TFVects_test.todense()]\n",
    "\n",
    "#Add to df\n",
    "test_ng_df['nb_predict'] = clf_knearest.predict(np.stack(test_ng_df['vect'], axis=0))\n",
    "\n",
    "#Test\n",
    "print(\"Testing score:\")\n",
    "print(clf_knearest.score(np.stack(test_ng_df['vect'], axis=0), test_ng_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's produce another confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucem_illud_2020.plotConfusionMatrix(clf_knearest, test_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can produce the PCA space visual if you want, altough it can take a very long time, so we'll leave it optionally commented out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lucem_illud_2020.plotregions(clf_knearest, test_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 4*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform and visualize k-nearest neighbor classification using training, testing and extrapolation (uncoded) data from texts and hand-classifications associated with your final project. Visualize the classification of data points and calculate relevant metrics (e.g., precision, recall, the F-measure, and AUC). Articulate how the *k*-nearest neighbor approach relates to *k*-means clustering explored in ***week 3***?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SVMs\n",
    "\n",
    "Now we will examine Support Vector Machines, an approach that creates the partition that preserves the \"maximum margin\" between classes.\n",
    "\n",
    "We will use a few sub forums from reddit--which tend to share text rather than memes--namely `talesfromtechsupport`, `badroommates`, `weeabootales` and `relationships`. The top 100 text posts from each have been saved to `data/reddit.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redditDf = pandas.read_csv('../data/reddit.csv', index_col = 0)\n",
    "\n",
    "#Drop a couple missing values\n",
    "\n",
    "redditDf = redditDf.dropna()\n",
    "\n",
    "#Set category\n",
    "\n",
    "redditDf['category'] = redditDf['subreddit']\n",
    "\n",
    "#tokenize and normalize\n",
    "redditDf['tokenized_text'] = redditDf['text'].apply(lambda x: lucem_illud_2020.word_tokenize(x))\n",
    "redditDf['normalized_text'] = redditDf['tokenized_text'].apply(lambda x: lucem_illud_2020.normalizeTokens(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will tf.idf the data to make our vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redditTFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=0.5, min_df=3, stop_words='english', norm='l2')\n",
    "redditTFVects = redditTFVectorizer.fit_transform([' '.join(l) for l in redditDf['normalized_text']])\n",
    "redditDf['vect'] = [np.array(v).flatten() for v in redditTFVects.todense()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initilize the model and make a train test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdBackFraction = .2\n",
    "train_redditDf, test_redditDf = lucem_illud_2020.trainTestSplit(redditDf, holdBackFraction=holdBackFraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = sklearn.svm.SVC(kernel='linear', probability = False)\n",
    "#probability = True is slower but  lets you call predict_proba()\n",
    "clf_svm.fit(np.stack(train_redditDf['vect'], axis=0), train_redditDf['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and consider the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucem_illud_2020.evaluateClassifier(clf_svm, test_redditDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucem_illud_2020.plotConfusionMatrix(clf_svm, test_redditDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucem_illud_2020.plotregions(clf_svm, test_redditDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Nets\n",
    "\n",
    "We include an example of a simple neural network, the Multi-layer Perceptron (MLP) that learns a function $f(\\cdot): R^m \\rightarrow R^o$ by training on a dataset, where $m$ is the number of dimensions for input and $o$ is the number of dimensions for output. Given a set of features $X = {x_1, x_2, ..., x_m}$ and a target $y$, it can learn a non-linear function approximator for either classification or regression. It is different from logistic regression, in that between the input and the output layer, there can be one or more non-linear layers, called hidden layers. The following figure shows a one hidden layer MLP with scalar output. ![title](../data/multilayerperceptron_network.png) The leftmost layer, known as the input layer, consists of a set of \"neurons\" $\\{x_i | x_1, x_2, ..., x_m\\}$ representing the input features (e.g., weighted words). Each neuron in the hidden layer transforms the values from the previous layer with a weighted linear summation $w_1x_1 + w_2x_2 + ... + w_mx_m$, followed by a non-linear activation function $g(\\cdot):R \\rightarrow R$ - like the logistic or hyperbolic tan function. The output layer receives the values from the last hidden layer and transforms them into output values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nn = sklearn.neural_network.MLPClassifier()\n",
    "clf_nn.fit(np.stack(train_redditDf['vect'], axis=0), train_redditDf['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucem_illud_2020.evaluateClassifier(clf_nn, test_redditDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucem_illud_2020.plotConfusionMatrix(clf_nn, test_redditDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucem_illud_2020.plotregions(clf_nn, test_redditDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It performs very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 5*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform a neural network classification and calculate relevant metrics (e.g., precision, recall, the F-measure, and AUC). How does this classify relevant to *k*-nearest neighbor, Naive Bayes, logistic and decision-tree approaches?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
